import whisper
import torch
import time
import openai
import os
from dotenv import load_dotenv
from pydub import AudioSegment

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ” í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {'GPU' if device == 'cuda' else 'CPU'}")

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("large-v3").to(device)

# .env íŒŒì¼ ë¡œë“œ ë° OpenAI API í‚¤ ì„¤ì •
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=api_key)

def wait_for_file(file_path, timeout=5):
    """íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
    start_time = time.time()
    while not os.path.exists(file_path):
        if time.time() - start_time > timeout:
            print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {file_path}")
            return False
        time.sleep(0.5)  # 0.5ì´ˆì”© ê¸°ë‹¤ë¦¼
    time.sleep(1)  # ì¶”ê°€ ëŒ€ê¸° (íŒŒì¼ ì €ì¥ ì™„ë£Œë  ì‹œê°„ì„ ì¤Œ)
    print(f"âœ… íŒŒì¼ ì €ì¥ í™•ì¸ ì™„ë£Œ: {file_path}")
    return True

def get_file_size(file_path):
    """íŒŒì¼ í¬ê¸° (MB ë‹¨ìœ„) ë°˜í™˜"""
    return os.path.getsize(file_path) / (1024 * 1024)

def split_audio_by_size(mp3_file, max_size_mb=20):
    """MP3 íŒŒì¼ì„ ì£¼ì–´ì§„ ìš©ëŸ‰ ì´í•˜ë¡œ ë¶„í• """
    audio = AudioSegment.from_mp3(mp3_file)
    total_size = get_file_size(mp3_file)

    # ë¶„í•  ê°œìˆ˜ ê³„ì‚° (20MB ë‹¨ìœ„)
    num_parts = int(total_size / max_size_mb) + 1
    segment_length = len(audio) // num_parts  # ê° íŒŒì¼ ê¸¸ì´ (ms)

    parts = []
    for i in range(num_parts):
        start_time = i * segment_length
        end_time = min((i + 1) * segment_length, len(audio))
        part_file = f"{mp3_file[:-4]}_part{i}.mp3"
        
        # ì˜¤ë””ì˜¤ ìŠ¬ë¼ì´ì‹± í›„ ì €ì¥
        audio[start_time:end_time].export(part_file, format="mp3", bitrate="64k")
        parts.append(part_file)

    return parts

def transcribe_audio_local(audio_file, output_text_file):
    print("ğŸ§  Whisper ë¡œì»¬ ë³€í™˜ ì‹œì‘...")
    start_time = time.time()
    result = model.transcribe(audio_file, language="ko")
    end_time = time.time()
    processing_time = round(end_time - start_time, 2)
    with open(output_text_file, "w", encoding="utf-8") as f:
        for segment in result["segments"]:
            f.write(f"{segment['text']}\n")
    print(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {output_text_file}")
    print(f"â³ Whisper ë¡œì»¬ ë³€í™˜ ì™„ë£Œ. ì‹¤í–‰ ì‹œê°„: {processing_time}ì´ˆ")
    print(f"ğŸš€ Whisper ì‹¤í–‰ ì¥ì¹˜: {'GPU' if device == 'cuda' else 'CPU'}")
    return output_text_file

def transcribe_audio_api(audio_file, output_text_file):
    print("â˜ï¸ OpenAI API ë³€í™˜ ì‹œì‘...")
    
    if not wait_for_file(audio_file, timeout=10):
        print("âŒ WAV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ë³€í™˜ ì¤‘ë‹¨.")
        return
    
    file_extension = os.path.splitext(audio_file)[1].lower()
    
    try:
        mp3_file = audio_file.replace(file_extension, ".mp3")
        audio = AudioSegment.from_file(audio_file, format=file_extension[1:])
        audio.export(mp3_file, format="mp3", bitrate="64k")
        print(f"ğŸ”„ {file_extension.upper()} â†’ MP3 ë³€í™˜ ì™„ë£Œ: {mp3_file}")
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
        return

    file_size = get_file_size(mp3_file)
    print(f"ğŸ“ MP3 íŒŒì¼ í¬ê¸°: {file_size:.2f}MB")

    if file_size > 25:
        print(f"âš ï¸ íŒŒì¼ í¬ê¸°ê°€ 25MB ì´ˆê³¼! ë¶„í•  ì§„í–‰ ì¤‘...")
        parts = split_audio_by_size(mp3_file, max_size_mb=20)
    else:
        parts = [mp3_file]
    
    all_text = []
    try:
        for part in parts:
            with open(part, "rb") as audio:
                response = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio,
                    language="ko",
                    response_format="verbose_json"
                )
            segments = response.segments if isinstance(response.segments, list) else list(response.segments)
            for segment in segments:
                all_text.append(f"{segment.text}")
            print(f"âœ… OpenAI API ë³€í™˜ ì™„ë£Œ: {part}")

    except Exception as e:
        print(f"âŒ OpenAI API ë³€í™˜ ì˜¤ë¥˜: {e}")
        return

    with open(output_text_file, "w", encoding="utf-8") as f:
        f.write("\n".join(all_text))

    print(f"âœ… ìµœì¢… ë³€í™˜ ì™„ë£Œ: {output_text_file}")
    return output_text_file
