import whisper
import torch
import time

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ” í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {'GPU' if device == 'cuda' else 'CPU'}")

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("large-v3").to(device)

def transcribe_audio(audio_file, output_text_file):
    print("ğŸ§  Whisper ë³€í™˜ ì‹œì‘...")
    
    start_time = time.time()  # ë³€í™˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    result = model.transcribe(audio_file, language="ko")  # ğŸ”¹ í•œêµ­ì–´ ê°•ì œ ì„¤ì •
    end_time = time.time()  # ë³€í™˜ ì™„ë£Œ ì‹œê°„ ê¸°ë¡
    processing_time = round(end_time - start_time, 2)

    # ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥
    with open(output_text_file, "w", encoding="utf-8") as f:
        f.write(result["text"])

    print(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {output_text_file}")
    print(f"â³ Whisper ë³€í™˜ ì™„ë£Œ. ì‹¤í–‰ ì‹œê°„: {processing_time}ì´ˆ")
    print(f"ğŸš€ Whisper ì‹¤í–‰ ì¥ì¹˜: {'GPU' if device == 'cuda' else 'CPU'}")